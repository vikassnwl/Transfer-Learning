{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 22:26:01.089492: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 22:26:01.095856: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-01 22:26:01.110673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-01 22:26:01.131778: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-01 22:26:01.137096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-01 22:26:01.152958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-01 22:26:02.458475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[test_set_raw, valid_set_raw, train_set_raw], info = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    ")\n",
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "class_names = info.features[\"label\"].names\n",
    "n_classes = info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "preprocess = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(224, 224, crop_to_aspect_ratio=True),\n",
    "    tf.keras.layers.Lambda(tf.keras.applications.xception.preprocess_input)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set_raw.map(lambda X, y: (preprocess(X), y))\n",
    "train_set = train_set.shuffle(1000, seed=42).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(lambda X, y: (preprocess(X), y)).batch(batch_size)\n",
    "test_set = test_set_raw.map(lambda X, y: (preprocess(X), y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    tf.keras.layers.RandomRotation(factor=0.05, seed=42),\n",
    "    tf.keras.layers.RandomContrast(factor=0.2, seed=42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model for a few epochs, its validation accuracy should reach a bit over 80% and then stop improving. This means that the top layers are now pretty well trained, and we are ready to unfreeze some of the base model's top layers, then continue training. For example, let's unfreeze layers 56 and above (that's the start of residual unit 7 out of 14, as you can see if you list the layer names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: input_layer_4          33: block4_pool            66: block8_sepconv1_act    99: block11_sepconv2_act  \n",
      "  1: block1_conv1           34: batch_normalization_2  67: block8_sepconv1       100: block11_sepconv2      \n",
      "  2: block1_conv1_bn        35: add_2                  68: block8_sepconv1_bn    101: block11_sepconv2_bn   \n",
      "  3: block1_conv1_act       36: block5_sepconv1_act    69: block8_sepconv2_act   102: block11_sepconv3_act  \n",
      "  4: block1_conv2           37: block5_sepconv1        70: block8_sepconv2       103: block11_sepconv3      \n",
      "  5: block1_conv2_bn        38: block5_sepconv1_bn     71: block8_sepconv2_bn    104: block11_sepconv3_bn   \n",
      "  6: block1_conv2_act       39: block5_sepconv2_act    72: block8_sepconv3_act   105: add_9                 \n",
      "  7: block2_sepconv1        40: block5_sepconv2        73: block8_sepconv3       106: block12_sepconv1_act  \n",
      "  8: block2_sepconv1_bn     41: block5_sepconv2_bn     74: block8_sepconv3_bn    107: block12_sepconv1      \n",
      "  9: block2_sepconv2_act    42: block5_sepconv3_act    75: add_6                 108: block12_sepconv1_bn   \n",
      " 10: block2_sepconv2        43: block5_sepconv3        76: block9_sepconv1_act   109: block12_sepconv2_act  \n",
      " 11: block2_sepconv2_bn     44: block5_sepconv3_bn     77: block9_sepconv1       110: block12_sepconv2      \n",
      " 12: conv2d                 45: add_3                  78: block9_sepconv1_bn    111: block12_sepconv2_bn   \n",
      " 13: block2_pool            46: block6_sepconv1_act    79: block9_sepconv2_act   112: block12_sepconv3_act  \n",
      " 14: batch_normalization    47: block6_sepconv1        80: block9_sepconv2       113: block12_sepconv3      \n",
      " 15: add                    48: block6_sepconv1_bn     81: block9_sepconv2_bn    114: block12_sepconv3_bn   \n",
      " 16: block3_sepconv1_act    49: block6_sepconv2_act    82: block9_sepconv3_act   115: add_10                \n",
      " 17: block3_sepconv1        50: block6_sepconv2        83: block9_sepconv3       116: block13_sepconv1_act  \n",
      " 18: block3_sepconv1_bn     51: block6_sepconv2_bn     84: block9_sepconv3_bn    117: block13_sepconv1      \n",
      " 19: block3_sepconv2_act    52: block6_sepconv3_act    85: add_7                 118: block13_sepconv1_bn   \n",
      " 20: block3_sepconv2        53: block6_sepconv3        86: block10_sepconv1_act  119: block13_sepconv2_act  \n",
      " 21: block3_sepconv2_bn     54: block6_sepconv3_bn     87: block10_sepconv1      120: block13_sepconv2      \n",
      " 22: conv2d_1               55: add_4                  88: block10_sepconv1_bn   121: block13_sepconv2_bn   \n",
      " 23: block3_pool            56: block7_sepconv1_act    89: block10_sepconv2_act  122: conv2d_3              \n",
      " 24: batch_normalization_1  57: block7_sepconv1        90: block10_sepconv2      123: block13_pool          \n",
      " 25: add_1                  58: block7_sepconv1_bn     91: block10_sepconv2_bn   124: batch_normalization_3 \n",
      " 26: block4_sepconv1_act    59: block7_sepconv2_act    92: block10_sepconv3_act  125: add_11                \n",
      " 27: block4_sepconv1        60: block7_sepconv2        93: block10_sepconv3      126: block14_sepconv1      \n",
      " 28: block4_sepconv1_bn     61: block7_sepconv2_bn     94: block10_sepconv3_bn   127: block14_sepconv1_bn   \n",
      " 29: block4_sepconv2_act    62: block7_sepconv3_act    95: add_8                 128: block14_sepconv1_act  \n",
      " 30: block4_sepconv2        63: block7_sepconv3        96: block11_sepconv1_act  129: block14_sepconv2      \n",
      " 31: block4_sepconv2_bn     64: block7_sepconv3_bn     97: block11_sepconv1      130: block14_sepconv2_bn   \n",
      " 32: conv2d_2               65: add_5                  98: block11_sepconv1_bn   131: block14_sepconv2_act  \n"
     ]
    }
   ],
   "source": [
    "for indices in zip(range(33), range(33, 66), range(66, 99), range(99, 132)):\n",
    "    for idx in indices:\n",
    "        print(f\"{idx:3}: {base_model.layers[idx].name:22}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[56:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to compile the model whenever you freeze or unfreeze layers. Also make sure to use a much lower learning rate to avoid damaging the pretrained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model should reach around 92% accuracy on the test set, in just a few minutes of training (with a GPU). If you tune the hyperparameters, lower the learning rate, and train for quite a bit longer, you should be able to reach 95% to 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
